{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Resource 3 & 4\n",
    "Filtering, vectorization, further filtering, umap-embedding, clustering and generation of the cluster-reports in markdown-format. Markdown-files can be concatenated and converted to .pdf using pandoc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaknowledge as mk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import datetime\n",
    "\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as scipy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For Tables:\n",
    "from IPython.display import display\n",
    "from IPython.display import Latex\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import json\n",
    "\n",
    "#For R (ggplot2)\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# from sklearn.externals.joblib import Memory\n",
    "# memory = Memory(cachedir='/tmp', verbose=0)\n",
    "# @memory.cache\n",
    "\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "#Embedding:\n",
    "import umap\n",
    "#Clustering:\n",
    "import hdbscan\n",
    "\n",
    "from itertools import count\n",
    "\n",
    "#set up dictionary for survey:\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the WOS-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_string = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "\n",
    "RC = mk.RecordCollection(\"wos_query.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecordCollection glimpse made at: 2019-06-15 22:46:51\n",
      "89467 Records from Empty\n",
      "\n",
      "Top Authors\n",
      "1 ANNAS, GJ\n",
      "2 Savulescu, Julian\n",
      "3 SHELAH, S\n",
      "4 HINTIKKA, J\n",
      "5 SOBER, E\n",
      "5 LEWIS, D\n",
      "6 Shelah, S\n",
      "7 JACKSON, F\n",
      "8 HACKING, I\n",
      "8 Miller, Franklin G.\n",
      "9 KITCHER, P\n",
      "9 Harris, J\n",
      "9 PETTIT, P\n",
      "10 LOWE, EJ\n",
      "11 NATSOULAS, T\n",
      "11 Savulescu, J\n",
      "12 Resnik, David B.\n",
      "12 Walton, Douglas\n",
      "12 Machery, Edouard\n",
      "13 Nanay, Bence\n",
      "13 VANFRAASSEN, BC\n",
      "\n",
      "Top Journals\n",
      "1 JOURNAL OF BUSINESS ETHICS\n",
      "2 JOURNAL OF MEDICAL ETHICS\n",
      "3 SYNTHESE\n",
      "4 JOURNAL OF SYMBOLIC LOGIC\n",
      "5 PHILOSOPHICAL STUDIES\n",
      "6 PHILOSOPHY OF SCIENCE\n",
      "7 CONSCIOUSNESS AND COGNITION\n",
      "8 HASTINGS CENTER REPORT\n",
      "9 JOURNAL OF PHILOSOPHY\n",
      "10 PHILOSOPHY AND PHENOMENOLOGICAL RESEARCH\n",
      "11 JOURNAL OF THE HISTORY OF IDEAS\n",
      "12 AMERICAN JOURNAL OF BIOETHICS\n",
      "13 ETHICS\n",
      "14 BRITISH JOURNAL FOR THE PHILOSOPHY OF SCIENCE\n",
      "15 MIND\n",
      "16 ANALYSIS\n",
      "17 CRITICAL INQUIRY\n",
      "18 NOUS\n",
      "19 SOCIAL RESEARCH\n",
      "20 JOURNAL OF MEDICINE AND PHILOSOPHY\n",
      "21 NURSING ETHICS\n",
      "\n",
      "Top Cited\n",
      "1 Rawls J, 1971, THEORY JUSTICE\n",
      "2 Parfit D., 1984, REASONS PERSONS\n",
      "3 Lewis D., 1986, PLURALITY WORLDS\n",
      "4 Nozick R., 1974, ANARCHY STATE UTOPIA\n",
      "5 Quine W. V. O., 1960, WORD OBJECT\n",
      "6 Lewis D, 1973, COUNTERFACTUALS\n",
      "7 Aristotle, NICOMACHEAN ETHICS\n",
      "8 Kripke Saul, 1980, NAMING NECESSITY\n",
      "9 vanFraassen B, 1980, SCI IMAGE\n",
      "10 Plato, REPUBLIC\n",
      "11 Freeman R. E, 1984, STRATEGIC MANAGEMENT\n",
      "12 Ryle G, 1949, CONCEPT MIND\n",
      "13 Williamson Timothy, 2000, KNOWLEDGE ITS LIMITS\n",
      "14 Kuhn TS, 1970, STRUCTURE SCI REVOLU\n",
      "15 DAVIDSON D., 1980, ESSAYS ACTIONS EVENT\n",
      "16 Wittgenstein Ludwig, 1953, PHILOS INVESTIGATION\n",
      "17 RAWLS JOHN, 1993, POLITICAL LIBERALISM, p[217, 212]\n",
      "18 James W, 1890, PRINCIPLES PSYCHOL\n",
      "19 TREVINO LK, 1986, ACAD MANAGE REV, V11, P601, DOI 10.2307/258313\n",
      "20 Nozick R, 1981, PHILOS EXPLANATIONS, P414\n",
      "21 Evans G., 1982, VARIETIES REFERENCE\n"
     ]
    }
   ],
   "source": [
    "RC2 = mk.RecordCollection()\n",
    "\n",
    "for R in RC:\n",
    "#     print(R)\n",
    "\n",
    "    try:\n",
    "        R['year']\n",
    "        if R['Z9']>=4:\n",
    "            RC2.add(R) #Here we keep only records cited more then three times.\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "\n",
    "print(RC2.glimpse())\n",
    "RC = RC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Cited Works - Features ############\n",
    "\n",
    "\n",
    "drc = pd.DataFrame.from_dict(RC.forNLP(extraColumns=['journal','AU','FU','PD']))\n",
    "\n",
    "def processInput(R):\n",
    "    d = list(set(R.getCitations().get(\"citeString\")))\n",
    "    citedAU = list(set(R.getCitations().get(\"author\")))\n",
    "    return d, citedAU\n",
    " \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(processInput)(R) for R in RC)\n",
    "\n",
    "\n",
    "d, citedAU = map(list, zip(*results))\n",
    "\n",
    "\n",
    "drc[\"citedAU\"] = citedAU\n",
    "drc[\"citestring\"] = d\n",
    "authorslist = ['ยง'.join(filter(None,x)) for x in list(d)] \n",
    "vec = CountVectorizer(token_pattern=r'(?<=[ยง])[\\s\\w,\\.:;\\/\\[\\]-]+(?=[ยง])',binary=True, min_df = 3)\n",
    "\n",
    "\n",
    "Xrc = vec.fit_transform(authorslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [Xrc]#XrcAu,\n",
    "XrcFull = scipy.sparse.hstack(k).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering papers to ensure connectedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = np.array(drc[\"id\"])\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "def filtersparse(x):\n",
    "    row_idx, = np.where(row_names == drc[\"id\"][x])\n",
    "    if np.diff(XrcFull[row_idx].tocsr().indptr) >= 3:\n",
    "        k = [XrcFull[row_idx]]\n",
    "        newdf = drc.loc[x]\n",
    "        return k, newdf\n",
    "    \n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=1)(delayed(filtersparse)(x) for x in range(0,XrcFull.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [x for x in results if x is not None]\n",
    "k, newdf = [e[0][0] for e in results], [e[1] for e in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_out = drc[~drc['id'].isin(pd.DataFrame(newdf)['id'])]\n",
    "filtered_out.to_csv('filtered_out.csv') #saving the dropped records for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc = pd.DataFrame(newdf).reset_index()\n",
    "M = scipy.sparse.vstack(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11232364652506363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "SVD = TruncatedSVD(n_components=400, n_iter=7, random_state=42)\n",
    "\n",
    "XSVD = SVD.fit_transform(M)\n",
    "print(SVD.explained_variance_ratio_.sum())\n",
    "dSVD = pd.DataFrame(XSVD)\n",
    "\n",
    "sSVD = dSVD[[0,1]]\n",
    "sSVD.columns = ['x','y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [UMAP](https://github.com/lmcinnes/umap)-Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_neighbors = 50,#small => local, large => global: 5-50\n",
    "                      min_dist = 0.17, #small => local, large => global: 0.001-0.5\n",
    "                      spread = 1.7,\n",
    "                      random_state = 42,\n",
    "                      metric='cosine').fit_transform(XSVD)\n",
    "embedding = pd.DataFrame(embedding)\n",
    "embedding.columns = ['x','y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddingL = umap.UMAP(n_components=30,\n",
    "                        n_neighbors=50,\n",
    "                      min_dist=0,\n",
    "                        random_state = 42,\n",
    "                      metric='cosine').fit(M).embedding_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=300, min_samples=45, gen_min_span_tree=True)\n",
    "clusterer.fit(embeddingL)\n",
    "XCLUST = clusterer.labels_\n",
    "clusternum = len(set( clusterer.labels_))-1\n",
    "\n",
    "dfclust = pd.DataFrame(XCLUST)\n",
    "dfclust.columns = ['cluster']\n",
    "\n",
    "print(clusternum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('hdb.pickle', 'wb') as f:\n",
    "    pickle.dump(clusterer, f) # save for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate the clustering-report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drc = pd.concat([drc, dfclust],axis=1)\n",
    "drc = drc.dropna(subset=['cluster'])\n",
    "drc = pd.concat([drc, embedding],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc.to_csv(\"drcend.csv\")\n",
    "\n",
    "drc = pd.read_csv(\"drcend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc['text'] = drc['title'].fillna('') + drc['abstract'].fillna('') + ' ' + drc['keywords'].fillna('').str.replace('|', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# This uses code from here: https://stackoverflow.com/questions/49564176/python-nltk-more-efficient-way-to-extract-noun-phrases\n",
    "# Defining a grammar & Parser\n",
    "NP = \"NP: {(<JJ\\w+>|<NN\\w?>)+.*<NN\\w?>}\" # Extract Noun-Phrases\n",
    "chunker = RegexpParser(NP)\n",
    "stopWords = ['article','paper','essay','i','elsevier','inc']\n",
    "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
    "    words=word_tokenize(text)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "        \n",
    "    chunked = chunk_func(pos_tag(wordsFiltered))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree:\n",
    "            current_chunk.append(\" \".join([lemmatizer.lemmatize(token) for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(lemmatizer.lemmatize(named_entity))\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "    return continuous_chunk\n",
    "\n",
    "\n",
    "drc['nplemma'] = drc['text'].replace(np.nan, '', regex=True).apply(lambda sent: get_continuous_chunks(sent, chunker.parse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc['npstring'] = [';'.join(map(str, l)) for l in drc['nplemma']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case study                             707\n",
       "business ethic                         634\n",
       "health care                            442\n",
       "decision making                        440\n",
       "responsibility csr                     293\n",
       "quantum mechanic                       183\n",
       "climate change                         162\n",
       "virtue ethic                           162\n",
       "research ethic                         161\n",
       "higher level                           156\n",
       "better understanding                   142\n",
       "research participant                   142\n",
       "stakeholder theory                     138\n",
       "higher education                       131\n",
       "research project                       126\n",
       "health professional                    126\n",
       "decision maker                         117\n",
       "business practice                      117\n",
       "corporate social responsibility        114\n",
       "research program                       111\n",
       "research study                         103\n",
       "best interest                          102\n",
       "research question                      101\n",
       "ethic committee                        101\n",
       "business student                        99\n",
       "family member                           98\n",
       "policy maker                            92\n",
       "starting point                          91\n",
       "set theory                              90\n",
       "health service                          87\n",
       "                                      ... \n",
       "parallel dynamical systemsin             1\n",
       "parallel cooperative                     1\n",
       "parallel complexity                      1\n",
       "parallel augustine view                  1\n",
       "parallel argumentthis                    1\n",
       "paralipomena ad vitellionem              1\n",
       "paralogics p                             1\n",
       "paralympic amputee oscar pistorius       1\n",
       "parameter matrix                         1\n",
       "paralympic gold medallist                1\n",
       "parameter independence                   1\n",
       "parameter history composition            1\n",
       "parameter hidden                         1\n",
       "parameter family                         1\n",
       "parameter correlation                    1\n",
       "parameter contributes                    1\n",
       "parameter combination                    1\n",
       "parameter change                         1\n",
       "parameter adaptation law                 1\n",
       "paralysisclimate scepticism              1\n",
       "paralysis isp                            1\n",
       "paralysis exoskeleton                    1\n",
       "paralysis distress                       1\n",
       "paralysis attack vigilance evidence      1\n",
       "paralysis attack                         1\n",
       "paralysis arises                         1\n",
       "paralysis anosognosia                    1\n",
       "paralysing impasse                       1\n",
       "paralyse thinking                        1\n",
       "% proof lakatos                          1\n",
       "Length: 202945, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer(token_pattern=r'[^;]+')\n",
    "X = vec.fit_transform(drc['npstring'])\n",
    "display(pd.DataFrame(X.sum(axis=0),columns=vec.get_feature_names()).sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stopWords = ['article','paper','essay','i','elsevier','inc','verlag','gmbh','springer']\n",
    "\n",
    "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
    "    chunked = word_tokenize(text)\n",
    "    tokens = []\n",
    "    for token in chunked:\n",
    "        tokens.append(lemmatizer.lemmatize(token))\n",
    "    words = [word for word,tag in pos_tag(chunked) if tag == 'NN']\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered\n",
    "\n",
    "drc['wordlemma'] = drc['text'].replace(np.nan, '', regex=True).apply(lambda sent: get_continuous_chunks(sent, chunker.parse))\n",
    "drc['wordlemmastring'] = [';'.join(map(str, l)) for l in drc['wordlemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(token_pattern=r'[^;]+')\n",
    "X = vec.fit_transform(drc['wordlemmastring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "research                 15312\n",
       "theory                   14070\n",
       "study                     9364\n",
       "analysis                  7628\n",
       "approach                  6351\n",
       "role                      6345\n",
       "model                     6342\n",
       "view                      6180\n",
       "health                    6060\n",
       "account                   6004\n",
       "work                      5788\n",
       "knowledge                 5711\n",
       "science                   5616\n",
       "care                      5524\n",
       "information               5479\n",
       "business                  5371\n",
       "way                       5360\n",
       "problem                   5234\n",
       "argument                  5185\n",
       "case                      5160\n",
       "practice                  5146\n",
       "nature                    5019\n",
       "concept                   4856\n",
       "time                      4777\n",
       "development               4755\n",
       "philosophy                4611\n",
       "evidence                  4576\n",
       "use                       4380\n",
       "process                   4374\n",
       "context                   4295\n",
       "                         ...  \n",
       "mountcastle                  1\n",
       "movements                    1\n",
       "mountaintop                  1\n",
       "mountaineering               1\n",
       "mounce                       1\n",
       "mounain                      1\n",
       "moulton                      1\n",
       "moulin                       1\n",
       "moulen                       1\n",
       "movementmany                 1\n",
       "movementsover                1\n",
       "mpc                          1\n",
       "movimento                    1\n",
       "mozilla                      1\n",
       "mozi                         1\n",
       "mozart                       1\n",
       "moyse                        1\n",
       "moyalsharrock                1\n",
       "mowshowitz                   1\n",
       "movingaverage                1\n",
       "moviesin                     1\n",
       "movementssensorimotor        1\n",
       "movethe                      1\n",
       "movementtomovement           1\n",
       "movementtime                 1\n",
       "movementthis                 1\n",
       "movementswe                  1\n",
       "movementsthe                 1\n",
       "movementsstimuli             1\n",
       "lessthanorequaltoeta         1\n",
       "Length: 57741, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(X.sum(axis=0),columns=vec.get_feature_names()).sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullstrsl = []\n",
    "for x in range(0,clusternum):\n",
    "    abstracts = list(drc.loc[drc['cluster'] == x]['wordlemma'])\n",
    "    abstracts = \";\".join(';'.join(x) for x in abstracts)\n",
    "    fullstrsl.append(abstracts)\n",
    "    \n",
    "vec = TfidfVectorizer(token_pattern=r'[^;]+')\n",
    "X = vec.fit_transform(fullstrsl)\n",
    "# display(pd.DataFrame(X.toarray(), columns=vec.get_feature_names()))\n",
    "\n",
    "clusterfeatures = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "fullscore = []\n",
    "\n",
    "surveypages = []\n",
    "for x in range(0,clusternum):\n",
    "    scores = zip(vec.get_feature_names(), np.asarray(X[x,:].sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    myscores = sorted_scores[0:20]\n",
    "\n",
    "    with open(\"report/mds/Cluster_Nr.%03i.md\" %x, \"w\") as text_file:\n",
    "\n",
    "        text_file.write('# Cluster ' + str(x) +'\\n')\n",
    "\n",
    "        text_file.write('![](img/Cluster_Nr_'+str(x)+'.png){width=100%}\\n\\n')\n",
    "        text_file.write('![](img_time/Cluster_Nr_'+str(x)+'.png){width=100%}\\n\\n')\n",
    "\n",
    "        text_file.write('## Nouns \\n')\n",
    "        text_file.write('\\\\colorlet{mytextcolor}{black}\\n\\n')\n",
    "        grams = [i[0] for i in myscores]\n",
    "        occs = [i[1] for i in myscores]\n",
    "        k = []\n",
    "        for it in range(0,len(grams)):\n",
    "            k.append('\\\\textcolor{mytextcolor!'+str((occs[it]/(max(occs)/100))*0.5+50)+'}{'+str(grams[it])+'}')\n",
    "        text_file.write(' \\\\textbullet{} '.join(k))\n",
    "        text_file.write('\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "    page = {}\n",
    "    page[\"name\"] = \"page\"+str(x)\n",
    "    elements = []\n",
    "    elements.append({\"type\": \"html\",\"name\": \"nouns\",\"html\": \"<h2> Nouns </h2>\"})\n",
    "\n",
    "    spans = []\n",
    "    for it in range(0,len(grams)):\n",
    "        spans.append('<span style=\\\"opacity:'+str(((occs[it]/(max(occs)/100))*0.01)*0.6+0.4)+';\\\">'+str(grams[it])+'</span>')\n",
    "        \n",
    "    elements.append({\"type\": \"html\",\"name\": \"nouns\",\"html\": str(' &#9679; '.join(spans))})\n",
    "\n",
    "    page[\"elements\"] = elements\n",
    "    #Build json for survey;\n",
    "    surveypages.append(page)\n",
    "  \n",
    "    \n",
    "    scorelist = []\n",
    "    for s in myscores:\n",
    "        scorelist.append(s[0])\n",
    "    fullscore.append(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fullstrsl = []\n",
    "for x in range(0,clusternum):\n",
    "    abstracts = list(drc.loc[drc['cluster'] == x]['nplemma'])\n",
    "    abstracts = \";\".join(';'.join(x) for x in abstracts)\n",
    "    fullstrsl.append(abstracts)\n",
    "    \n",
    "vec = TfidfVectorizer(token_pattern=r'[^;]+')\n",
    "X = vec.fit_transform(fullstrsl)\n",
    "# display(pd.DataFrame(X.toarray(), columns=vec.get_feature_names()))\n",
    "\n",
    "clusterfeatures = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "fullscore = []\n",
    "\n",
    "surveypages = []\n",
    "for x in range(0,clusternum):\n",
    "    scores = zip(vec.get_feature_names(), np.asarray(X[x,:].sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    myscores = sorted_scores[0:20]\n",
    "    \n",
    "    with open(\"report/mds/Cluster_Nr.%03i.md\" %x, \"a\") as text_file:\n",
    "        text_file.write('\\n## Noun phrases \\n')\n",
    "        text_file.write('\\\\colorlet{mytextcolor}{black}\\n\\n')\n",
    "        grams = [i[0] for i in myscores]\n",
    "        occs = [i[1] for i in myscores]\n",
    "        k = []\n",
    "        for it in range(0,len(grams)):\n",
    "            k.append('\\\\textcolor{mytextcolor!'+str((occs[it]/(max(occs)/100))*0.5+50)+'}{'+str(grams[it])+'}')\n",
    "#             k.append('\\\\textcolor{mytextcolor!'+str(1)+'}{'+str(grams[it])+'}')\n",
    "\n",
    "        text_file.write(' \\\\textbullet{} '.join(k))\n",
    "        text_file.write('\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "    page = {}\n",
    "    page[\"name\"] = \"page\"+str(x)\n",
    "    elements = []\n",
    "    elements.append({\"type\": \"html\",\"name\": \"Noun phrases\",\"html\": \"<h2> Unigrams </h2>\"})\n",
    "\n",
    "    spans = []\n",
    "    for it in range(0,len(grams)):\n",
    "        spans.append('<span style=\\\"opacity:'+str(((occs[it]/(max(occs)/100))*0.01)*0.6+0.4)+';\\\">'+str(grams[it])+'</span>')\n",
    "        \n",
    "    elements.append({\"type\": \"html\",\"name\": \"unigrams\",\"html\": str(' &#9679; '.join(spans))})\n",
    "\n",
    "    page[\"elements\"] = elements\n",
    "    surveypages.append(page)\n",
    "  \n",
    "    \n",
    "    scorelist = []\n",
    "    for s in myscores:\n",
    "        scorelist.append(s[0])\n",
    "    fullscore.append(scorelist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {}\n",
    "keys = range(clusternum)\n",
    "for i in keys:\n",
    "        dicts[i] = mk.RecordCollection()\n",
    "\n",
    "for R in RC:\n",
    "    try: \n",
    "        dicts[drc.loc[drc['id'] == R['id']]['cluster'].values[0]].add(R)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import slugify\n",
    "for x in keys:\n",
    "    dicts[x].writeFile(\"clusters_filtered/\"+ (str(x))[0:100] +\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for x in keys:\n",
    "\n",
    "    #JOURNALS\n",
    "    ranked_journals = dicts.get(x).rankedSeries('journal', giveCounts = True, giveRanks = False, pandasMode = False)\n",
    "    with open(\"report/mds/Cluster_Nr.%03i.md\" %x, \"a\") as text_file:\n",
    "        text_file.write('\\n## Journals \\n')\n",
    "\n",
    "        grams = [i[0] for i in ranked_journals[0:5]]\n",
    "        occs = [i[1] for i in ranked_journals[0:5]]\n",
    "        k = []\n",
    "        for it in range(0,len(grams)):\n",
    "            k.append('\\\\textcolor{mytextcolor!'+str((occs[it]/(max(occs)/100))*0.5+50)+'}{'+str(grams[it]).lower().title()+'}')\n",
    "        text_file.write(' \\\\textbullet{} '.join(k))\n",
    "        text_file.write('\\n')\n",
    "        \n",
    "    # Write survey:\n",
    "    \n",
    "    surveypages[x]['elements'].append({\"type\": \"html\",\"name\": \"Journals\",\"html\": \"<h2> Journals </h2>\"})\n",
    "    spans = []\n",
    "    for it in range(0,len(grams)):\n",
    "        spans.append('<span style=\\\"opacity:'+str(((occs[it]/(max(occs)/100))*0.01)*0.6+0.4)+';\\\">'+str(grams[it]).lower().title()+'</span>')\n",
    "        \n",
    "    surveypages[x]['elements'].append({\"type\": \"html\",\"name\": \"journals\",\"html\": str(' &#9679; '.join(spans))})\n",
    "\n",
    "    # CITED RECORDS:\n",
    "    ranked_citations = dicts.get(x).rankedSeries('CR', giveCounts = True, giveRanks = False, pandasMode = False)\n",
    "    with open(\"report/mds/Cluster_Nr.%03i.md\" %x, \"a\") as text_file:\n",
    "        text_file.write('\\n## Most Cited Works \\n')\n",
    "\n",
    "        grams = [i[0] for i in ranked_citations[0:15]]\n",
    "        occs = [i[1] for i in ranked_citations[0:15]]\n",
    "        k = []\n",
    "        for it in range(0,len(grams)):\n",
    "            k.append('\\\\textcolor{mytextcolor!'+str((occs[it]/(max(occs)/100))*0.5+50)+'}{'+str(grams[it]).lower().title()\n",
    "                     .replace('_','\\_')+'}')\n",
    "        text_file.write(' \\\\textbullet{} '.join(k))\n",
    "        text_file.write('\\n')\n",
    "    \n",
    "        # Write survey:\n",
    "    \n",
    "    surveypages[x]['elements'].append({\"type\": \"html\",\"name\": \"works\",\"html\": \"<h2> Most cited works </h2> <p> You can click on underlined titles to find out what they are!</p>\"})\n",
    "    spans = []\n",
    "    for it in range(0,len(grams)):\n",
    "        if getattr(grams[it], 'DOI'):\n",
    "#             print(getattr(grams[it], 'DOI'))\n",
    "            spans.append('<a href=\\\"https://doi.org/'+str(getattr(grams[it], 'DOI')).replace('DOI:','').replace('DOI','').replace(' ','').replace(':','\\:')+\n",
    "                         '\\\" target=\\\"_blank\\\"><span style=\\\"opacity:'+str(((occs[it]/(max(occs)/100))*0.01)*0.6+0.4)+';\\\">'+\n",
    "                         str(getattr(grams[it],'author')).lower().title()+', '+str(getattr(grams[it],'year'))+'</span></a>')\n",
    "        else:\n",
    "            spans.append('<span style=\\\"opacity:'+str(((occs[it]/(max(occs)/100))*0.01)*0.6+0.4)+';\\\">'+str(getattr(grams[it],'author')).lower().title()+', '+str(getattr(grams[it],'year'))+'</span>')\n",
    "\n",
    "    surveypages[x]['elements'].append({\"type\": \"html\",\"name\": \"journals\",\"html\": str(' &#9679; '.join(spans))})\n",
    "    \n",
    "    surveypages[x]['elements'].append({\"type\": \"text\",\"name\": str(\"cluster\"+str(x)),\"title\": \"Please propose one or several names for this cluster:\",\"placeHolder\": \"\"})\n",
    "    surveypages[x]['elements'].append({\"type\": \"rating\",\"name\": str(\"certitude\"+str(x)),\"title\": \"How certain are you in your choice?\",\n",
    "                                       \"minRateDescription\": \"Very uncertain\", \"maxRateDescription\": \"Completely certain\"})\n",
    "\n",
    "    surveypages[x]['elements'].append({\"type\": \"radiogroup\",\"name\": \"exit1\",\"title\": \"Do you need to end the survey?\",\n",
    "                    \"choices\": [\"Yes\"],\"colCount\": 0})   \n",
    "    \n",
    "# Set up survey:\n",
    "survey = {}\n",
    "survey[\"triggers\"] = [{\"type\": \"complete\",\"name\": \"exit1\",\"operator\": \"equal\",\"value\": \"Yes\"}, {\"type\": \"complete\",\"name\": \"exit2\",\"operator\": \"equal\",\"value\": \"Yes\"}]\n",
    "    \n",
    "survey[\"firstPageIsStarted\"] = True\n",
    "survey[\"startSurveyText\"] = \"Start Survey\"\n",
    "#add landing-page:\n",
    "surveypages = [{\"name\": \"landing\",\"elements\": [{\"type\": \"html\",\"name\": \"landing\",\"html\": \"<h2>A survey on the econ literature </h2> In this survey we will ask you to identify some clusters of the economic literature.\"}]}] + surveypages\n",
    "survey[\"pages\"] = surveypages\n",
    "# print(json.dumps(survey))\n",
    "survey = json.dumps(survey)\n",
    "parsed = json.loads(survey)\n",
    "with open('survey/survey.json', 'w') as outfile:\n",
    "    json.dump(parsed, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
